# -*- coding: utf-8 -*-
"""Data Analytics Conversation agent using Langchain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JKhPiu5h9Xh-CTzoXfHhRHB2epIEJmqj

### Data Analytics conversational Agent using Langchain ###

1.1 Load Required Libraries
"""

!pip install langchain langchain-openai pandas openai tabulate

"""1.2 Load Dataset"""

from google.colab import drive
drive.mount('/content/drive')

"""1.3 Load API Key"""

open_api_key= '/content/drive/MyDrive/OpenAI_API_Key.txt'

laptop_data= '/content/drive/MyDrive/laptop_data.csv'

!pip install -U langchain langchain-openai langchain-community langchain-experimental

!pip uninstall langchain langchain-core langchain-community langchain-openai langchain-experimental -y

!pip install langchain==0.3.14
!pip install langchain-openai==0.2.14
!pip install langchain-community==0.3.14
!pip install langchain-experimental==0.3.4

"""1.4 Function to execute the Data analytical agent"""

import os
import pandas as pd
from langchain_openai import ChatOpenAI
from langchain_experimental.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent
from langchain.memory import ConversationBufferMemory
from langchain.agents.agent_types import AgentType
from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain.agents import AgentType

# =========================
# STEP 1: Set OpenAI API Key
# =========================

# Option 1: If using local notebook
with open(open_api_key, "r") as f:
  os.environ["OPENAI_API_KEY"] = f.read().strip()

# Option 2 (recommended): Uncomment if using .env
# from dotenv import load_dotenv
# load_dotenv()

# =========================
# STEP 2: Load Dataset
# =========================

# Replace with your dataset
df = pd.read_csv(laptop_data)

print("Dataset loaded successfully.")
print(df.head())


# =========================
# STEP 3: Initialize LLM
# =========================

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0
)


# =========================
# STEP 4: Create Memory
# =========================

memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)


# =========================
# STEP 5: Create Data Analytics Agent
# =========================

agent = create_pandas_dataframe_agent(
    llm=llm,
    df=df,
    agent_type=AgentType.OPENAI_FUNCTIONS,  # FIX
    verbose=True,
    allow_dangerous_code=True,
    max_iterations=15,
    max_execution_time=120
)


# =========================
# STEP 6: Greeting Message
# =========================

print("\nAgent: Hello! ðŸ‘‹")
print("Agent: I am your Data Analytics Assistant.")
print("Agent: I can help you analyze your dataset.")
print("Agent: Please tell me how can I help you?\n")


# =========================
# STEP 7: Conversation Loop
# =========================

while True:

    user_input = input("You: ")

    # Exit conditions
    if user_input.lower() in [
        "exit",
        "thank you no further questions",
        "thank you",
        "bye"
    ]:
        print("\nAgent: Thank you for using the Data Analytics Assistant.")
        print("Agent: Have a great day! ðŸ‘‹")
        break

    try:

        # Add instruction to agent
        prompt = f"""
        User Question: {user_input}

        Instructions:
        - Answer ONLY using the dataset provided.
        - If answer is not available in dataset, say exactly:
          "My knowledge is limited to the provided dataset and I do not know the answer."
        - Provide clear and helpful explanation.
        """

        prompt2 = f"""
You are a professional Data Analytics Assistant working strictly with a pandas dataframe named `df`.

User Question:
{user_input}

Context:
- The dataframe `df` contains the dataset.
- All answers MUST be derived only from this dataframe.
- Do NOT use external knowledge.
- Do NOT make assumptions beyond the dataset.

Analytical Instructions:
- Use pandas operations to analyze the dataframe (e.g., filtering, aggregation, grouping, statistics).
- Ensure calculations are accurate and based on actual data.
- If the question involves statistics, compute exact values.
- If the question involves columns, refer to df.columns and df.dtypes.
- If the question involves trends, comparisons, or summaries, perform proper analysis.

Response Guidelines:
- Provide a clear, precise, and professional answer.
- Explain insights in simple and understandable terms.
- Include relevant numbers, column names, and findings.
- Do NOT include code in the final answer.
- Do NOT describe internal reasoning steps.

Strict Limitation Rule:
- If the answer cannot be determined from the dataframe, respond EXACTLY with:
"My knowledge is limited to the provided dataset and I do not know the answer."

Output Format:
- Provide only the final answer.
- Keep the response concise but informative.
"""

        response = agent.invoke(prompt2)

        print("\nAgent:", response, "\n")

    except Exception as e:

        print("\nAgent: My knowledge is limited to the provided dataset and I do not know the answer.\n")

!pip install -U langchain langchain-openai langchain-community

!pip install langchain

!pip install langchain-experimental